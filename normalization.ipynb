{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a109388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10439 13075 14161 13046 13703 11576\n",
      "11345 10985 11168 14225 10945 13951\n",
      "12804 12455 12675 12857 14285 14320\n",
      "12341 11823 15161 14042 14042 13619\n",
      "10550 13676 11580 13398 12611 15237\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "index = 'price'\n",
    "df_1 = pd.read_hdf('./h30/fc25/'+index+'.h5')\n",
    "df_1 = df_1.sample(frac=1).reset_index(drop=True)\n",
    "df_2 = pd.read_hdf('./h30/fc30/'+index+'.h5')\n",
    "df_2 = df_2.sample(frac=1).reset_index(drop=True)\n",
    "df_3 = pd.read_hdf('./h30/fc35/'+index+'.h5')\n",
    "df_3 = df_3.sample(frac=1).reset_index(drop=True)\n",
    "df_4 = pd.read_hdf('./h30/fc40/'+index+'.h5')\n",
    "df_4 = df_4.sample(frac=1).reset_index(drop=True)\n",
    "df_5 = pd.read_hdf('./h30/fc45/'+index+'.h5')\n",
    "df_5 = df_5.sample(frac=1).reset_index(drop=True)\n",
    "df_6 = pd.read_hdf('./h30/fc50/'+index+'.h5')\n",
    "df_6 = df_6.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_7 = pd.read_hdf('./h40/fc25/'+index+'.h5')\n",
    "df_7 = df_7.sample(frac=1).reset_index(drop=True)\n",
    "df_8 = pd.read_hdf('./h40/fc30/'+index+'.h5')\n",
    "df_8 = df_8.sample(frac=1).reset_index(drop=True)\n",
    "df_9 = pd.read_hdf('./h40/fc35/'+index+'.h5')\n",
    "df_9 = df_9.sample(frac=1).reset_index(drop=True)\n",
    "df_10 = pd.read_hdf('./h40/fc40/'+index+'.h5')\n",
    "df_10 = df_10.sample(frac=1).reset_index(drop=True)\n",
    "df_16 = pd.read_hdf('./h40/fc45/'+index+'.h5')\n",
    "df_16 = df_16.sample(frac=1).reset_index(drop=True)\n",
    "df_17 = pd.read_hdf('./h40/fc50/'+index+'.h5')\n",
    "df_17 = df_17.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_11 = pd.read_hdf('./h50/fc25/'+index+'.h5')\n",
    "df_11 = df_11.sample(frac=1).reset_index(drop=True)\n",
    "df_12 = pd.read_hdf('./h50/fc30/'+index+'.h5')\n",
    "df_12 = df_12.sample(frac=1).reset_index(drop=True)\n",
    "df_13 = pd.read_hdf('./h50/fc35/'+index+'.h5')\n",
    "df_13 = df_13.sample(frac=1).reset_index(drop=True)\n",
    "df_14 = pd.read_hdf('./h50/fc40/'+index+'.h5')\n",
    "df_14 = df_14.sample(frac=1).reset_index(drop=True)\n",
    "df_15 = pd.read_hdf('./h50/fc45/'+index+'.h5')\n",
    "df_15 = df_15.sample(frac=1).reset_index(drop=True)\n",
    "df_18 = pd.read_hdf('./h50/fc50/'+index+'.h5')\n",
    "df_18 = df_18.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_19 = pd.read_hdf('./h35/fc25/'+index+'.h5')\n",
    "df_19 = df_19.sample(frac=1).reset_index(drop=True)\n",
    "df_20 = pd.read_hdf('./h35/fc30/'+index+'.h5')\n",
    "df_20 = df_20.sample(frac=1).reset_index(drop=True)\n",
    "df_21 = pd.read_hdf('./h35/fc35/'+index+'.h5')\n",
    "df_21 = df_21.sample(frac=1).reset_index(drop=True)\n",
    "df_22 = pd.read_hdf('./h35/fc40/'+index+'.h5')\n",
    "df_22 = df_22.sample(frac=1).reset_index(drop=True)\n",
    "df_23 = pd.read_hdf('./h35/fc45/'+index+'.h5')\n",
    "df_23 = df_23.sample(frac=1).reset_index(drop=True)\n",
    "df_24 = pd.read_hdf('./h35/fc50/'+index+'.h5')\n",
    "df_24 = df_24.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_25 = pd.read_hdf('./h45/fc25/'+index+'.h5')\n",
    "df_25 = df_25.sample(frac=1).reset_index(drop=True)\n",
    "df_26 = pd.read_hdf('./h45/fc30/'+index+'.h5')\n",
    "df_26 = df_26.sample(frac=1).reset_index(drop=True)\n",
    "df_27 = pd.read_hdf('./h45/fc35/'+index+'.h5')\n",
    "df_27 = df_27.sample(frac=1).reset_index(drop=True)\n",
    "df_28 = pd.read_hdf('./h45/fc40/'+index+'.h5')\n",
    "df_28 = df_28.sample(frac=1).reset_index(drop=True)\n",
    "df_29 = pd.read_hdf('./h45/fc45/'+index+'.h5')\n",
    "df_29 = df_29.sample(frac=1).reset_index(drop=True)\n",
    "df_30 = pd.read_hdf('./h45/fc50/'+index+'.h5')\n",
    "df_30 = df_30.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(len(df_1), len(df_2), len(df_3), len(df_4), len(df_5), len(df_6))\n",
    "print(len(df_7), len(df_8), len(df_9), len(df_10), len(df_11), len(df_12))\n",
    "print(len(df_13), len(df_14), len(df_15), len(df_16), len(df_17), len(df_18))\n",
    "print(len(df_19), len(df_20), len(df_21), len(df_22), len(df_23), len(df_24))\n",
    "print(len(df_25), len(df_26), len(df_27), len(df_28), len(df_29), len(df_30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd9f0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P           float64\n",
       "My          float64\n",
       "Mz          float64\n",
       "Width       float64\n",
       "Depth       float64\n",
       "As_total    float64\n",
       "h           float64\n",
       "fc            int64\n",
       "price       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10439\n",
    "df_1 = df_1.append([df_16[:n], df_2[:n], df_4[:n], df_5[:n], df_7[:n], df_8[:n], df_9[:n], df_10[:n],df_11[:n], df_12[:n], df_13[:n], df_14[:n],df_15[:n], df_17[:n], df_18[:n]])\n",
    "df_1 = df_1.append([df_19[:n], df_20[:n], df_21[:n], df_22[:n], df_23[:n], df_24[:n],df_25[:n], df_26[:n], df_27[:n], df_28[:n], df_29[:n], df_30[:n]])\n",
    "\n",
    "\n",
    "#df_1['numRebars'] = df_1['numRebars'].astype(float, errors = 'raise')\n",
    "\n",
    "#df_1['fc'] = df_1['fc'].astype(float, errors = 'raise')\n",
    "df_1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716d401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.sample(frac=1).reset_index(drop=True)\n",
    "#df.loc[:,'fc'] *= -1\n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train = df[:round(len(df)*0.85)]\n",
    "\n",
    "train_norm = (train - train.min())/(train.max() - train.min())\n",
    "train_min = train.min()\n",
    "train_max = train.max()\n",
    "\n",
    "train.to_hdf(\"train.h5\", key='w')\n",
    "train_min.to_hdf(\"train_min.h5\", key='w')\n",
    "train_max.to_hdf(\"train_max.h5\", key='w')\n",
    "train_norm.to_hdf(\"train_norm.h5\", key='w')\n",
    "\n",
    "val = df[round(len(df)*0.85):round(len(df)*0.95)]\n",
    "val.to_hdf(\"val.h5\", key='w')\n",
    "val_norm = (val - train.min()) / (train.max() - train.min())\n",
    "val_norm.to_hdf(\"val_norm.h5\", key='w')\n",
    "\n",
    "test = df[round(len(df)*0.95):]\n",
    "test.to_hdf(\"test.h5\", key='w')\n",
    "test_norm = (test - train.min()) / (train.max() - train.min())\n",
    "test_norm.to_hdf(\"test_norm.h5\", key='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_array = np.array([[500, 100, 100, 3.0, 25],\n",
    "                      [500, 100, 1000, 3.0, 30],\n",
    "                      [500, 1000, 1000, 3.0, 35],\n",
    "                      [5000, 100, 100, 3.0, 40],\n",
    "                      [5000, 100, 1000, 3.0, 45],\n",
    "                      [5000, 1000, 1000, 3.0, 50],\n",
    "                      [500, 100, 100, 3.5, 25],\n",
    "                      [500, 100, 1000, 3.5, 30],\n",
    "                      [500, 1000, 1000, 3.5, 35],\n",
    "                      [5000, 100, 100, 3.5, 40],\n",
    "                      [5000, 100, 1000, 3.5, 45],\n",
    "                      [5000, 1000, 1000, 3.5, 50],\n",
    "                      [500, 100, 100, 4.0, 25],\n",
    "                      [500, 100, 1000, 4.0, 30],\n",
    "                      [500, 1000, 1000, 4.0, 35],\n",
    "                      [5000, 100, 100, 4.0, 40],\n",
    "                      [5000, 100, 1000, 4.0, 45],\n",
    "                      [5000, 1000, 1000, 4.0, 50],\n",
    "                       [500, 100, 100, 4.5, 25],\n",
    "                      [500, 100, 1000, 4.5, 30],\n",
    "                      [500, 1000, 1000, 4.5, 35],\n",
    "                      [5000, 100, 100, 4.5, 40],\n",
    "                      [5000, 100, 1000, 4.5, 45],\n",
    "                      [5000, 1000, 1000, 4.5, 50],\n",
    "                       [500, 100, 100, 5.0, 25],\n",
    "                       [500, 100, 1000, 5.0, 30],\n",
    "                       [500, 1000, 1000, 5.0, 35],\n",
    "                       [5000, 100, 100, 5.0, 40],\n",
    "                       [5000, 100, 1000, 5.0, 45],\n",
    "                       [5000, 1000, 1000, 5.0, 50] ])\n",
    "#test_array = test_array[:2]/1000\n",
    "\n",
    "test_frame = pd.DataFrame(test_array, columns = ['P', 'My', 'Mz', 'h','fc'])\n",
    "\n",
    "#test_frame = test_frame.iloc[: , :-1]\n",
    "\n",
    "test_frame['P'] = test_frame['P']/1000\n",
    "test_frame['My'] = test_frame['My']/1000\n",
    "test_frame['Mz'] = test_frame['Mz']/1000\n",
    "#test_frame['fc'] = -test_frame['fc']\n",
    "train = pd.read_hdf(\"train.h5\")\n",
    "#train['fc']= (-1)*train['fc']\n",
    "train_min = train.min()\n",
    "train_max = train.max()\n",
    "train_min = train_min.drop(['As_total', 'Width', 'Depth'])\n",
    "\n",
    "\n",
    "train_max = train_max.drop(['As_total', 'Width', 'Depth'])\n",
    "\n",
    "test_samples_normalized =  (test_frame - train_min) / (train_max - train_min)\n",
    "\n",
    "test_samples_normalized.to_hdf(\"test_samples.h5\", key='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3116458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_hdf(\"price_visual.h5\", key='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328deaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea824403",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b7ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
